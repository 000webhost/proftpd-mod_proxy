
ProxyBackendSelection random roundRobin leastConns perUser per

  lib/proxy/filetable.c
    for reading a pr_table_t from file on disk.  Overkill?

  on startup event, iterate through configured backend servers, mark which
  ones cannot be connected to as "dead".
    Means backend server list management, with attributes:
      server:
        connCount
        connectTime
        lastChecked

    Or, better: TWO lists: live list, dead list

    For tracking connectTime (time to connect, in millisecs):

      long timevaldiff(struct timeval *starttime, struct timeval *finishtime) {
        long msec;
        msec=(finishtime->tv_sec-starttime->tv_sec)*1000;
        msec+=(finishtime->tv_usec-starttime->tv_usec)/1000;
        return msec;
      }

      struct timeval start, finish;
      long msec;

      gettimeofday(&start, NULL);
      sleep(1);
      gettimeofday(&finish, NULL);
      msec = timevaldiff(&start, &finish);
      printf("Elapsed time for sleep(1) is: %d milliseconds.\n", msec);

    Some platforms have a timersub(3) macro for this, but it'll be more
    portable to do our own.

Simple balancing (selection at connect time):

  random

  round robin
    (requires pre-fork event to be added to core)
    Note: For "ServerType inetd", roundrobin cannot be supported (no process
      for tracking state)

  least conns
    (requires pre-fork event to be added to core, state to be maintained by
     mod_proxy)

  equal distribution (all servers have same number of conns)
    (requires pre-fork event to be added to core, state to be maintained by
     mod_proxy)

  Note: for any of these, if the initially selected backend refuses the
  connection (tcp connect fails, or response code non-2xxx returned), then
  need to select next from "live" list, and so on.  Should the number of
  "retry nexts" be configurable?

Advanced balancing (selection at USER time):

  random

  round robin

  least conns

  equal distribution

  user-specific (lookup per user)

Complex/adaptive balancing:

  Client IP address/class (connect time selection)
  FTP USER (i.e. user affinity to specific server(s)) (USER time selection)
    lookup AND hashed (algo?  Same algo used by Table API?)
  SSL/TLS session ID/resumption/ticket
  SSL/TLS protocol version (AUTH time selection)
  SSL/TLS ciphersuite (AUTH time selection)
  Backend response time (connect time selection)

Balancing Versus Stickiness

For reverse proxy configurations, there is a choice between "balancing"
strategies and "sticky" strategies when it comes to selecting the backend 
server that will handle the incoming connection.

Which should you use, and why?

All of the "balancing" strategies are able to select the backend server *at
connect time*.  Most of the "sticky" strategies, on the other hand, require
more knowledge about the user (e.g. USER name, HOST name, SSL session ID),
thus backend server selection is delayed until that information is obtained.

Balancing is best when all of your backend severs are identical with regard to
the content they have, AND when it doesn't matter which server handles a
particular client.  Maybe all of your backend servers use a shared filesystem
via NFS or similar, thus directory listings will be the same for a user no
matter which backend server is used, and uploading files to one server means
that those files can be downloaded/seen by the other servers.

Stickiness is best when your backend servers are NOT identical, and some
users/clients should only ever go to some particular set of backend servers.
Thus the user/client needs to be "sticky" to a given backend server(s) --
that's when you need the sticky selection strategies.
